{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation_Transformer_Scaled_Dot_Product.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11wnzCnHGK0oJef51Qy3ifBhV-ODNbYHT",
      "authorship_tag": "ABX9TyPpoc3X2JG9QkE4q+UYxq6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfriLANG4/fNMTxhen/blob/master/Translation_Transformer_Scaled_Dot_Product.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5ComgCgciHK",
        "colab_type": "text"
      },
      "source": [
        "source:[ fastai / course-nlp ](https://https://github.com/fastai/course-nlp/blob/master/8-translation-transformer.ipynb)\n",
        "\n",
        "source:[CyndxAI](https://github.com/CyndxAI/CyndxAI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmdF4LT0oOfh",
        "colab_type": "code",
        "outputId": "f4f17b33-e9ea-439c-b871-0ef64ab6e8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "from fastai.text import *\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW7ewsjxqQvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_word_count = 40\n",
        "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    samples = to_data(samples)\n",
        "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "        else:         \n",
        "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
        "    return res_x, res_y\n",
        "\n",
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
        "               pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        cp_args = dict(dl_kwargs)\n",
        "        del cp_args['dl_tfms']\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **cp_args)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **cp_args))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
        "    \n",
        "\n",
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList\n",
        "    \n",
        "def shift_tfm(b):\n",
        "    x,y = b\n",
        "    y = F.pad(y, (1, 0), value=1)\n",
        "    return [x,y[:,:-1]], y[:,1:]\n",
        "    \n",
        "    \n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"Encode the position with a sinusoid.\"\n",
        "    def __init__(self, d:int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
        "    \n",
        "    def forward(self, pos:Tensor):\n",
        "        inp = torch.ger(pos, self.freq)\n",
        "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
        "        return enc\n",
        "    \n",
        "    \n",
        "class TransformerEmbedding(nn.Module):\n",
        "    \"Embedding + positional encoding + dropout\"\n",
        "    def __init__(self, vocab_sz:int, emb_sz:int, inp_p:float=0.):\n",
        "        super().__init__()\n",
        "        self.emb_sz = emb_sz\n",
        "        self.embed = embedding(vocab_sz, emb_sz)\n",
        "        self.pos_enc = PositionalEncoding(emb_sz)\n",
        "        self.drop = nn.Dropout(inp_p)\n",
        "    \n",
        "    def forward(self, inp): \n",
        "        pos = torch.arange(0, inp.size(1), device=inp.device).float()\n",
        "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))\n",
        "    \n",
        "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., double_drop:bool=True):\n",
        "    layers = [nn.Linear(d_model, d_ff), nn.ReLU()]\n",
        "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
        "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
        "\n",
        "\n",
        "def scaling_factor(query_size):\n",
        "    return np.log2((query_size**2) - query_size)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"MutiHeadAttention.\"\n",
        "    \n",
        "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
        "                 scale:bool=True,  max_word_count = max_word_count, attn_mode='dot'):\n",
        "        super().__init__()\n",
        "        d_head = ifnone(d_head, d_model//n_heads)\n",
        "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
        "        self.q_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.k_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.v_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
        "        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "        self.max_word_count = max_word_count\n",
        "        self.attn_mode = attn_mode\n",
        "        \n",
        "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
        "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask))))\n",
        "    \n",
        "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
        "        bs,seq_len = q.size(0),q.size(1)\n",
        "        wq,wk,wv = self.q_wgt(q),self.k_wgt(k),self.v_wgt(v)\n",
        "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
        "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
        "        if self.attn_mode == 'cosine':\n",
        "            wq = F.normalize(wq, p=2, dim=-1)\n",
        "            wk = F.normalize(wk, p=2, dim=-1)\n",
        "            attn_score = torch.matmul(wq, wk)\n",
        "            if self.scale: attn_score = attn_score.mul_(scaling_factor(self.max_word_count)) \n",
        "        elif self.attn_mode =='dot':\n",
        "            attn_score = torch.matmul(wq, wk)\n",
        "            if self.scale: attn_score = attn_score.div_(self.d_head ** 0.5)\n",
        "        else:\n",
        "            raise Exception('attn_mode must be specified')\n",
        "        if mask is not None: \n",
        "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
        "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
        "        attn_vec = torch.matmul(attn_prob, wv)\n",
        "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, seq_len, -1)\n",
        "        \n",
        "    def _attention_einsum(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
        "        # Permute and matmul is a little bit faster but this implementation is more readable\n",
        "        bs,seq_len = q.size(0),q.size(1)\n",
        "        wq,wk,wv = self.q_wgt(q),self.k_wgt(k),self.v_wgt(v)\n",
        "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
        "        if self.attn_mode == 'cosine':\n",
        "            wq = F.normalize(wq, p=2, dim=-1)\n",
        "            wk = F.normalize(wk, p=2, dim=-1)\n",
        "            attn_score = torch.einsum('bind,bjnd->bijn', (wq, wk))\n",
        "            if self.scale: attn_score = attn_score.mul_(scaling_factor(max_word_count))\n",
        "        elif self.attn_mode =='dot':\n",
        "            attn_score = torch.einsum('bind,bjnd->bijn', (wq, wk))\n",
        "            if self.scale: attn_score = attn_score.mul_(1/(self.d_head ** 0.5))\n",
        "        else:\n",
        "            raise Exception('attn_mode must be specified')\n",
        "        if mask is not None: \n",
        "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
        "        attn_prob = self.drop_att(F.softmax(attn_score, dim=2))\n",
        "        attn_vec = torch.einsum('bijn,bjnd->bind', (attn_prob, wv))\n",
        "        return attn_vec.contiguous().view(bs, seq_len, -1)\n",
        "    \n",
        "def get_padding_mask(inp, pad_idx:int=1):\n",
        "    return None\n",
        "    return (inp == pad_idx)[:,None,:,None]\n",
        "\n",
        "def get_output_mask(inp, pad_idx:int=1):\n",
        "    return torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None].bool()\n",
        "    return ((inp == pad_idx)[:,None,:,None].long() + torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None] != 0)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"Encoder block of a Transformer model.\"\n",
        "    #Can't use Sequential directly cause more than one input...\n",
        "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
        "                 bias:bool=True, scale:bool=True, double_drop:bool=True, max_word_count = max_word_count, attn_mode='dot'):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale,\n",
        "                                     max_word_count = max_word_count, attn_mode=attn_mode)\n",
        "        self.ff  = feed_forward(d_model, d_inner, ff_p=ff_p, double_drop=double_drop)\n",
        "    \n",
        "    def forward(self, x:Tensor, mask:Tensor=None): return self.ff(self.mha(x, x, x, mask=mask))\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"Decoder block of a Transformer model.\"\n",
        "    #Can't use Sequential directly cause more than one input...\n",
        "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
        "                 bias:bool=True, scale:bool=True, double_drop:bool=True, max_word_count = max_word_count, attn_mode='dot'):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale, \n",
        "                                       max_word_count = max_word_count, attn_mode=attn_mode)\n",
        "        self.mha2 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale,\n",
        "                                      max_word_count = max_word_count, attn_mode=attn_mode)\n",
        "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, double_drop=double_drop)\n",
        "    \n",
        "    def forward(self, x:Tensor, enc:Tensor, mask_in:Tensor=None, mask_out:Tensor=None): \n",
        "        y = self.mha1(x, x, x, mask_out)\n",
        "        return self.ff(self.mha2(y, enc, enc, mask=mask_in))\n",
        "    \n",
        "class Transformer(nn.Module):\n",
        "    \"Transformer model\"\n",
        "    \n",
        "    def __init__(self, inp_vsz:int, out_vsz:int, n_layers:int=6, n_heads:int=8, d_model:int=256, d_head:int=32, \n",
        "                 d_inner:int=1024, inp_p:float=0.1, resid_p:float=0.1, attn_p:float=0.1, ff_p:float=0.1, bias:bool=True, \n",
        "                 scale:bool=True, double_drop:bool=True, pad_idx:int=1, max_word_count = max_word_count, attn_mode='dot'):\n",
        "        super().__init__()\n",
        "        self.enc_emb = TransformerEmbedding(inp_vsz, d_model, inp_p)\n",
        "        self.dec_emb = TransformerEmbedding(out_vsz, d_model, 0.)\n",
        "        self.encoder = nn.ModuleList([EncoderBlock(n_heads, d_model, d_head, d_inner, resid_p, attn_p, \n",
        "                                                   ff_p, bias, scale, double_drop, max_word_count, attn_mode) for _ in range(n_layers)])\n",
        "        self.decoder = nn.ModuleList([DecoderBlock(n_heads, d_model, d_head, d_inner, resid_p, attn_p, \n",
        "                                                   ff_p, bias, scale, double_drop, max_word_count, attn_mode) for _ in range(n_layers)])\n",
        "        self.out = nn.Linear(d_model, out_vsz)\n",
        "        self.out.weight = self.dec_emb.embed.weight\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    def forward(self, inp, out):\n",
        "        mask_in  = get_padding_mask(inp, self.pad_idx)\n",
        "        mask_out = get_output_mask (out, self.pad_idx)\n",
        "        enc,out = self.enc_emb(inp),self.dec_emb(out)\n",
        "        for enc_block in self.encoder: enc = enc_block(enc, mask_in)\n",
        "        for dec_block in self.decoder: out = dec_block(out, enc, mask_in, mask_out)\n",
        "        return self.out(out)\n",
        "    \n",
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
        "    def __eq__(self, other):\n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))\n",
        "\n",
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]\n",
        "\n",
        "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
        "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
        "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)\n",
        "\n",
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "    \n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.corrects[i] += c\n",
        "                self.counts[i]   += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
        "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
        "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)\n",
        "\n",
        "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
        "    learn.model.eval()\n",
        "    inputs, targets, outputs = [],[],[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(*xb)\n",
        "            for x,y,z in zip(xb[0].cpu(),xb[1].cpu(),out.cpu()):\n",
        "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
        "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
        "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
        "    return inputs, targets, outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abjk7gGXm8JI",
        "colab_type": "code",
        "outputId": "aad9f19f-0478-43f9-b7a9-bce2ed03e189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from pathlib import Path\n",
        "from fastai import *\n",
        "path = Path('/content/drive/My Drive/afrilang4/memat/data');path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/afrilang4/memat/data')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVt60S6nAhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYGJYgPct7KB",
        "colab_type": "code",
        "outputId": "cbfbe922-8c7a-4501-d0ee-5e5f5a0e5469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "data.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj umzekelo , umqhubi wamashumi amabini anesine samawaka eekilowadzi xxunk oqhubela phambili xxunk amabini anamashumi xxunk amawaka omlinganiselo wesantya xxunk xxunk ipetroyile sele xxunk sangqa xxunk elinesiqingatha xxunk seemitha , kwaye inobunzima obumalunga namashumi amathandathu omlinganiselo wesantya senqanawa .</td>\n",
              "      <td>xxbos xxmaj for example , the propeller for a xxunk kw propulsion plant on a xxunk tanker already has a diameter of 9.4 metres , and it weighs nearly 60 tons .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos 1 xxmaj community xxmaj safety xxmaj barometer project 2009 / 10 , xxmaj south xxmaj african xxmaj police xxmaj annual report 2009 / 10 , xxup saps xxmaj performance xxmaj plan 2010 / 11 , xxup saps xxunk crime</td>\n",
              "      <td>xxbos 1 xxmaj community xxmaj safety xxmaj barometer project 2009 / 10 , xxmaj south xxmaj african xxmaj police xxmaj annual report 2009 / 10 , xxup saps xxmaj performance xxmaj plan 2010 / 11 , xxup saps reported crime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos wenze iziseko zesilivere , zibe mashumi mane phantsi xxunk ezimashumi mabini : zibe zibini iziseko , phantsi kweplanga inye , zeempondlo zayo zombini ; zibe zibini iziseko , phantsi kweplanga inye , zeempondlo zayo zombini .</td>\n",
              "      <td>xxbos xxmaj you shall make forty sockets of silver under the twenty boards ; two sockets under one board for its two tenons , and two sockets under another board for its two tenons .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj ukutyala ukutshintsha kwindlela ( ukugoba komgca xxunk ngomoya ojikeleza umhlaba ) le nto yenzeka ingakumbi xa umbindi welanga uvela njengomgca ohamba ukusuka kwicala ukuya kwelinye udlula kumbindi wesangqa ngaphezulu komgca odibanisa isibhakabhaka nomhlaba .</td>\n",
              "      <td>xxbos xxmaj owing to refraction ( the bending of the light rays by the atmosphere ) this actually occurs when the sun 's centre appears to be about its own diameter above the horizon .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj ulwaphulo- mthetho olufuna xxmaj ulwaphulo - mthetho xxmaj ulwaphulo - mthetho xxmaj ulwaphulo- mthetho xxmaj ingqwalaselo : 2 xxmaj olufuna ingqwalaselo : 3 xxmaj olufuna ingqwalaselo : 4 4 xxmaj olufuna ingqwalaselo : 5</td>\n",
              "      <td>xxbos that the xxup cpf meetings need to be held more regularly for more effective service to the community</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5H4_rczxDAB",
        "colab_type": "text"
      },
      "source": [
        "##Training with **Dot Product**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKzthuQUnAeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_x_vocab,n_y_vocab = len(data.train_ds.x.vocab.itos), len(data.train_ds.y.vocab.itos)\n",
        "\n",
        "model = Transformer(n_x_vocab, n_y_vocab, d_model=256)\n",
        "learn = Learner(data, model, metrics=[accuracy, CorpusBLEU(n_y_vocab)], loss_func = CrossEntropyFlat())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRVSLizVkh4Z",
        "colab_type": "text"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJOhw2zjuE54",
        "colab_type": "code",
        "outputId": "8e3a7133-4144-495f-812b-841c5b71898c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='90' class='' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      5.04% [90/1785 00:11<03:44 20.9844]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cc8yLXVuSRU",
        "colab_type": "code",
        "outputId": "93f51a75-39d6-4bb2-a2de-3dc78c38d5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "learn.fit_one_cycle(7, 5e-4, div_factor=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.150355</td>\n",
              "      <td>2.444598</td>\n",
              "      <td>0.630891</td>\n",
              "      <td>0.458480</td>\n",
              "      <td>03:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.765127</td>\n",
              "      <td>1.984807</td>\n",
              "      <td>0.677447</td>\n",
              "      <td>0.495137</td>\n",
              "      <td>03:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.538007</td>\n",
              "      <td>1.754475</td>\n",
              "      <td>0.704304</td>\n",
              "      <td>0.520698</td>\n",
              "      <td>03:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.380166</td>\n",
              "      <td>1.613502</td>\n",
              "      <td>0.723137</td>\n",
              "      <td>0.540376</td>\n",
              "      <td>03:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.200720</td>\n",
              "      <td>1.551993</td>\n",
              "      <td>0.735764</td>\n",
              "      <td>0.555758</td>\n",
              "      <td>03:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.045485</td>\n",
              "      <td>1.537179</td>\n",
              "      <td>0.739438</td>\n",
              "      <td>0.561781</td>\n",
              "      <td>03:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.949996</td>\n",
              "      <td>1.547592</td>\n",
              "      <td>0.739663</td>\n",
              "      <td>0.562139</td>\n",
              "      <td>03:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT4G0bNzuXIy",
        "colab_type": "code",
        "outputId": "60384601-37b8-4114-856d-633f58328c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='446' class='' max='446' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [446/446 00:54<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mKFLM3yuYEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save(path/'trans_7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQjaJzDgWjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.recorder.plot_losses(st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty4Edw7FupA7",
        "colab_type": "code",
        "outputId": "7c6d972a-6a1f-415a-c315-db84ee75044c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "print(inputs[10],'\\n',targets[10],'\\n',outputs[10],'\\n')\n",
        "print(inputs[700],'\\n',targets[700],'\\n',outputs[700],'\\n')\n",
        "# print(inputs[701],'\\n',targets[701],'\\n',outputs[701]),'\\n')\n",
        "print(inputs[2500],'\\n',targets[2500],'\\n',outputs[2500],'\\n')\n",
        "print(inputs[4002],'\\n',targets[4002],'\\n',outputs[4002],'\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xxbos xxmaj amanzi , ingakumbi amanzi xxunk , xxunk umbane , kwaye ukuba athe adibana nesixhobo zikanomathotholo isixhobo sokunqanda umbane xxunk xxunk kwaye xxunk eziphezulu xxunk , nto leyo enokuthi ibangele umlilo kunye nomonakalo omandundu kuzo zonke izixhobo . \n",
            " xxbos xxmaj water , especially salt water , conducts electricity , and if it reaches radio equipment the insulators will be rendered useless and the high voltages will flash over , causing burning and serious damage throughout the equipment \n",
            " xxbos xxmaj water , especially water water , is electricity , and if a is radio equipment , radio can be used by and can fire fire , cause and all which fire and damage damage to the fire . \n",
            "\n",
            "xxbos amakaledi athetha ke kukumkani xxunk , athi , xxmaj kumkani , yidla ubomi ngonaphakade ! xxmaj xxunk abakhonzi bakho iphupha elo ; xxunk ukutyhilwa kwalo . \n",
            " xxbos xxmaj then spoke the xxmaj chaldeans to the king in the xxmaj syrian language , o king , live forever : tell your servants the dream , and we will show the interpretation . \n",
            " xxbos xxmaj the the to xxmaj chaldeans , the king , the king chaldeans , , and king , eat forever ! eat your servants , dream which and what will show you interpretation of \n",
            "\n",
            "xxbos xxmaj babefuna abasebenzi abangamakhulu mane anamashumi asixhenxe ( 470 ) kuthelekiswa namakhulu amabini anamashumi amathandathu ( 260 ) ezangoku xxunk . \n",
            " xxbos xxmaj they needed a crew of xxunk compared with the 260 of the later xxmaj leanders . \n",
            " xxbos xxmaj they had forty hundred of forty tons with xxunk xxunk of about xxmaj xxmaj xxunk . \n",
            "\n",
            "xxbos xxmaj abathe , xxmaj ulwimi lwethu xxunk ; xxmaj imilomo yethu xxunk ; ngubani na xxunk kuthi ? \n",
            " xxbos who have said , \" xxmaj with our tongue we will prevail . xxmaj our lips are our own . xxmaj who is lord over us ? \" \n",
            " xxbos xxmaj , understanding , \" xxmaj our our tongue , are be . xxmaj who tongue xxunk xxunk own , xxmaj who can not , us ? \" \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}